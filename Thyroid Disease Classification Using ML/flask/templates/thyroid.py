# -*- coding: utf-8 -*-
"""Thyroid.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ropWE5LoAyFDv5E8f0tZ_58fQ8DitPSu

**Importing the libraries**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt 
import tensorflow
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Layer, Dense, Dropout

"""**Read the Dataset**"""

# Read the dataset into a Pandas DataFrame
df = pd.read_csv('/content/drug200.csv')

df.head()

df.shape

"""**Data Pre-processing**"""

df.isnull().sum()

# Encode categorical variables as one-hot vectors
df = pd.DataFrame(df, columns=['Sex', 'BP', 'Cholesterol'])

#Removing Redundant attributes from dataset
df['BP'].fillna(df['BP'].mode()[0], inplace=True)
df['Cholesterol'].fillna(df['Cholesterol'].mode()[0], inplace=True)
df['Na_to_K'].fillna(df['Na_to_K'].median(), inplace=True)

# re-mapping target values to diagnostic group
diagnoses = {'drugA': 'A',
             'drugB': 'B', 
             'drugC': 'C',
             'drugX': 'D',
             'drugY': 'E'}

df['Drug'] = df['Drug'].map(diagnoses)

# Drop rows with null values
df.dropna(subset=['Drug'],inplace=True)

df['Drug'].value_counts()

# Check for values above 100 in 'age' column
age_above_100 = df[df['Age'] > 100]

"""**Splitting the data x and y**"""

# Split the data values as x and y
x = df.iloc[:,0:-1]
y = df.iloc[:,-1]

x

x['Sex'].unique()

x['Sex'].replace(np.nan, 'F', inplace=True)

x['Sex'].value_counts()

"""**Converting the data type**"""

x['Age'] = x['Age'].astype(float)

x.info()

"""**Handling Categorical Values**"""

#Encoding the categorical data
#Encoding the independent(output)variable
from sklearn.preprocessing import OrdinalEncoder,LabelEncoder
# Categorical data

ordinal_encoder = OrdinalEncoder(dtype='int64')
x.iloc[:, 1:16] = ordinal_encoder.fit_transform(x.iloc[:, 1:16])
#ordinal_encoder.fit_transform(x[['Sex]])

x

x.replace(np.nan, '0',inplace=True)

x

label_encoder = LabelEncoder()
y_dt=label_encoder.fit_transform(y)

y=pd.DataFrame(y_dt,columns=['target'])

y

"""**Splitting data into train and test**"""

# Split the data values as x and y
x = df.iloc[:,0 :-1]
y = df.iloc[:, -1]

x

# Split the data into training and testing sets
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=0)

from imblearn.over_sampling import SMOTE
y_train.value_counts()

"""**Handling imbalanced data**"""

from imblearn.over_sampling import RandomOverSampler

ros = RandomOverSampler(random_state=42)
x_ros, y_ros = ros.fit_resample(x, y) # resample the original data to balance classes
x_bal, x_test_bal, y_bal, y_test_bal = train_test_split(x_ros, y_ros, test_size=0.2, random_state=42) # split into training and test set

"""**Applying StandardScaler**"""

# standardize the data using StandardScaler
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
#x_bal= scaler.fit_transform(x_bal)
#x_test_bal = scaler.transform(x_test_bal_enc)

columns=['Age','Sex','BP','Cholesterol','Na_to_K']

x_test_bal = pd.DataFrame(data=x_test, columns=columns)

x_bal= pd.DataFrame(x_bal,columns = columns)

x_bal

"""**Performing Feature Importance**"""

import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.inspection import permutation_importance
import numpy as np
import matplotlib.pyplot as plt

# Encode categorical features as numeric values
le = LabelEncoder()
for col in X.columns:
    if X[col].dtype == 'object':
        X[col] = le.fit_transform(X[col])

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create a random forest classifier
rfr = RandomForestClassifier(random_state=42)

# Fit the classifier to the training data
rfr.fit(X_train, y_train)

# Perform feature importance
results = permutation_importance(rfr, X_train, y_train, scoring='accuracy')

# Get feature importances
feature_importance = X_train.columns.tolist()
importance = results.importances_mean
importance = np.sort(importance)

# Summarize feature importance
for i, v in enumerate(importance):
    print('Feature: {:<20} Score: {}'.format(feature_importance[i], v))

# Plot feature importances
plt.figure(figsize=(10, 10))
plt.bar(x=feature_importance, height=importance)
plt.xticks(rotation=30, ha='right')
plt.xlabel('Feature')
plt.ylabel('Importance Score')
plt.title('Permutation Feature Importance')
plt.show()

x.head()

x_bal = x_bal.drop(['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K'], axis=1)

x_test_bal = x_test.drop(['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K'], axis=1)

x_bal.head()

"""**Exploratory Data Analysis**"""

df.info()

"""**Visual analysis**

**Checking Correlation**
"""

#checking correlation using Heatmap
import seaborn as sns
corrmat = x.corr()

f, ax = plt.subplots(figsize =(9,8))
sns.heatmap(corrmat, ax = ax,cmap = 'YlGnBu',linewidths = 0.1)

"""**Model Building**"""

# Train the rfr
from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier().fit(X_train,y_train.values.ravel())
rf = RandomForestClassifier()

rf.fit(X_train, y_train.values.ravel())

# Predict the target variable using the trained model
y_pred = rf.predict(X_test)

# Print the classification report
print(classification_report(y_test, y_pred))

# Evaluate the performance of the model using accuracy score
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

"""**XGBClassifier model**"""

from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score

# train XGBClassifier model
model = XGBClassifier()
model.fit(X_train, y_train)

# make predictions on test data
y_pred = model.predict(X_test)

print(classification_report(y_test,y_pred))

accuracy_score(y_test, y_pred)

"""**SVC model**"""

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score,classification_report
sv = SVC()

sv.fit(X_train,y_train)

y_pred = sv.predict(X_test)

print(classification_report(y_test,y_pred))

train_score = accuracy_score(y_test,sv.predict(X_test))
train_score

"""**ANN Model**"""

# create an ANN model
model = Sequential()

model.add(Dense(units = 128,activation='relu', input_shape=(10,)))

model.add(Dense(units=128, activation='relu', kernel_initializer='random_uniform'))
model.add(Dropout(0.2))
model.add(Dense(units=256, activation='relu', kernel_initializer='random_uniform'))
model.add(Dropout(0.2))
model.add(Dense(units=128, activation='relu', kernel_initializer='random_uniform'))

model.add(Dense(units = 1,activation='sigmoid'))

model.summary()

model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])

"""**Testing the model**"""

model.predict([[0,0,0,0,0.000000,0.0,0.0,1.00,0.0,40.0]])

params = {
      'C':[0.1,1,10,100,1000],
      'gamma':[1,0.1,0.01,0.001,0.0001],
      'kernel':['rdf','sqrt']
}

sv1=SVC(kernel='rbf',gamma=0.1,C=100)

#saving the mode
import pickle

pickle.dump(sv1,open('thyroid_1_model.pkl','wb'))

features = np.array([[0,0,0,0,0.000000,0.0,0.0,1.00,0.0,40.0]])

pickle.dump(label_encoder,open('label_encoder.pkl','wb'))

df['Drug'].unique()

"""**Model Deployment**"""

import pickle

pickle.dump(sv1,open('thyroid_1_model.pkl','wb'))